### 1. 1.3 데이터 레이크 아키텍처와 카프카의 미래

데이터 레이크 아키텍처의 종류는 2가지가 있다.

#### 첫 번째는 '람다 아키텍처 (lambda architecture)'

- 레거시 데이터 수집 플랫폼 (legacy data collect platform)을 개선하기 위해 구성한 아키텍처
- 초기 빅데이터 플랫폼은 앤드 투 엔드로 각 서비스 애플리케이션으로부터 데이터를 배치를 이용해서 모았다.
- 데이터를 배치로 모으는 구조는 유연하지 못했고, 실시간으로 생성되는 데이터에 대한 인사이트를 서비스 애플리케이션에 빠르게 전달하지 못했다.
    - 실시간으로 생성되는 데이터를 바로 보내야 하는데, 배치는 일정 기간을 두고 실행되므로 바로바로 전달하지 못한다.
- 원천 데이터로부터 파생된 데이터의 히스토리를 파악하기 어렵다.
    - 파생된 데이터가 어디서 왔는지, 언제 생성된 데이터인지 등등?? (개인적인 생각)
- 계속되는 데이터의 가공으로 인해 데이터가 파편화되면서 데이터 거버넌스를 지키기 어려웠다.
  - 데이터 파편화란?   
    - 데이터가 조각조각 분리되는 현상
  - 데이터 거버넌스란?   
    - 데이터 거버넌스는 기업에서 사용하는 데이터의 가용성, 유용성, 통합성, 보안성을 관리하기 위한 정책과 프로세스를 다루며 프라이버시, 보안성, 데이터품질, 관리규정 준수를 강조한다.
- 이를 해결하기 위해 기존의 배치 데이터를 처리하는 부분 외에 스피드 레이어라고 불리는 실시간 데이터 ETL작업 영역을 정의한 아키텍처를 만들었다.
  - 이 아키텍처가 람다 아키텍처
  - ETL?
    - 추출 (Extract), 변환 (Transform), 적재 (Load)
    - 조직에서 여러 시스템의 데이털르 단일 데이터베이스, 데이터 웨어하우스 또는 데이터 레이크에 결합하기 위해 일반적으로 허용하는 방법
- 배치 레이어
  - 배치 데이터를 모아서 특정 시간, 타이밍마다 일괄 처리한다.
- 서빙 레이어
  - 가공된 데이터를 데이터 사용자, 서비스 애플리케이션이 사용할 수 있도록 데이터가 저장된 공간이다.
- 스피드 레이어
  - 서비스에서 생성되는 원천 데이터르 실시간으로 분석하는 용도로 사용한다.
  - 배치 데이터에 비해 낮은 지연으로 분석이 필요한 경우에 스피드 레이어를 통해 데이터를 분석한다.
  - 분석, 가공한 데이터를 사용자 또는 서비스에서 직접 사용할 수 있지만 필요한 경우에는 서빙 레이어로 데이터를 보내서 저장하고 사용할 수 있다.
  - 카프카가 위치한 레이어이다.
- 배치 처리, 실시간 처리 레이어를 분리해 데이터 처리 방식을 명확히 나눴지만 그에 따른 단점도 있다.
- 분석, 처리하는 로직이 각각 두 군데 생성되어야 하고, 두 가지 방식을 융합할 때 유연하지 못하다.
- 로직 구현체 파편화를 해결하기 위해 로직을 추상화하여 배치, 스피드 레이어에 적용하는 형태를 고안한 서밍 버드 (summingbird)가 있었지만 컴파일 이후엔 각각 디버깅, 배포해야 했기 때문에 문제가 해결되지 않았다.


#### 두 번째는 '카파 아키텍처 (kappa architecture)'

- 람다 아키텍처의 문제점을 해결하기 위해 고안된 아키텍처
- 람다 아키텍처의 배치 레이어를 제거하고 모든 데이터를 스피드 레이어에 넣어서 처리한다.
- 로직 파편화, 디버깅, 배포, 운영 분리에 대한 이슈 제거했다.
- 하지만 스피드 레이어에서 모든 데이터를 처리하므로 서비스에서 생성되는 모든 종류의 데이터를 스트림 처리해야 한다.
- 배치 데이터
  - 초, 분, 시간 일 등으로 한정된(bounded) 기간 단위 데이터
  - 일괄 처리하는 것이 특징
  - 인터넷 쇼핑몰에서 지난 1분 간 주문한 제품 목록 2021년 신입생 목록
- 스트림 데이터
  - 한정되지 않은(unbounded) 데이터
  - 시작 데이터와 끝 데이터가 명확하지 않은 데이터
  - 사용자 클릭 로그, 사물 인터넷의 센서 데이터
- 배치 데이터를 스트림 프로세스를 처리할 수 있게 된 배경은 모든 데이터를 로그(log)로 바라보는 것에서 시작되었다.
- 여기서 로그는 일반적으로 생각하는 애플리케이션 로깅하는 텍스트 로그가 아니라 '데이터의 집합'을 뜻한다.
- 이 데이터는 지속적으로 추가가 가능하며 각 데이터에는 일정한 번호 또는 타임 스탬프가 붙는다.
- 배치 데이터를 표현할 때는 각 시점의 전체 데이터를 백업한 스냅샷 데이터를 뜻했다.
- 그러나 배치 데이터를 로그로 표현할 때는 각 시점의 배치 데이터 변환 기록 (change log)을 시간 순서대로 기록함으로써 각 시점의 모든 스냅샷 데이터를 저장하지 않고도 배치 데이터를 표현할 수 있게 되었다. -> 중요 !!!
  - 다시 말해서 전체 데이터 중 필요한 시점 별로 스냅샷을 저장하는게 아니라, 이벤트에 대해 로그를 쌓음으로써 해당 시점의 로그를 분석해서 배치 데이터를 얻을 수 있다.
- 로그로 배치와 스트림 데이터를 모두 사용하기 위해서는 변환 기록이 일정 기간동안 삭제되지 않고 추가되어야 한다.
- 그리고 서비스에서 생성되는 모든 데이터가 스피드 레이어도 들어오기 때문에 해당 데이터 플랫폼은 SPOF가 될 수 있으므로 반드시 HA와 fault tolerant 특징을 지녀야 했다.
- 카프카는 이런 특징에 정확히 부합하는 데이터 플랫폼이다.
- 카프카 내부에서 사용되는 파티션, 레코드, 오프셋은 제이 크렙스가 정의한 로그의 데이터 플랫폼 구현체로 볼 수 있다.


#### 제이 크렙스가 제안한 스트리밍 데이터 레이크 (streaming data lake)

- 카파 아키텍처에서 서빙 레이어를 제거한 아키텍처
- 스피드 레이어에서 분석, 가공한 데이터를 서빙 레이어 (HDFS, S3)에 저장하는데 스피드 레이어에서 이를 해결할 수 있다면?
  - 굳이 서빙 레이어가 필요 없어진다. -> 운영 리소스를 줄일 수 있게 된다.
- 스피드 레이어에서 데이터를 분석, 가공, 저장함으로써 SSOT(Single Source Of Truth)가 되는 것이다.
- 데이터가 필요한 모든 고객과 애플리케이션 서비스는 스피드 레이어만 참조함으로써 데이터 중복, 비정합과 같은 문제에서 벗어날 수 있다.